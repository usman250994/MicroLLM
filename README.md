# MicroLLM
A minimal in-memory LLM + RAG pipeline in Python. Demonstrates embeddings, vector search, and context-aware querying in just a few lines. Designed as a lightweight prototype, extendable later to chunking, persistent vector DBs, and AWS Lambda integration.
